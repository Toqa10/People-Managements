# -*- coding: utf-8 -*-
"""People Mangement

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QvJdwo0BWFABUs_tffoIl6uwGIscAfeU

**What Business Domain Does This Serve?
This is clearly from a corporate HR analytics system, supporting:**

ðŸ‘¨â€ðŸ’¼ Workforce Planning

ðŸ’° Compensation & Salary Strategy

ðŸš€ Promotion Path & Talent Development

ðŸ¢ Departmental Allocation

ðŸ§‘â€âš–ï¸ Manager Effectiveness

ðŸ“Š Gender Equity and Diversity Monitoring

## Employee Data
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd
dfE = pd.read_csv("employee.csv")

dfE.head()

# 1. Describe (categorical data)
print(dfE.describe(include='object'))

# 2. Info
print(dfE.info())

# 3. Null values
print(dfE.isnull().sum())

# 4. Duplicates
print(f"Duplicate rows: {dfE.duplicated().sum()}")

# 5. Data Validation
print(f"Unique first names: {dfE['first_name'].nunique()}")
print(f"Unique last names: {dfE['last_name'].nunique()}")

"""## Dep_Employee"""

from google.colab import files
uploaded = files.upload()

import pandas as pd

dfDE = pd.read_csv("department_employee.csv")
dfDE.head()

# 1. Describe (categorical data)
print(dfDE.describe(include='object'))

# 2. Info
print(dfDE.info())

# 3. Null values
print(dfDE.isnull().sum())

# 4. Duplicates
print(f"Duplicate rows: {dfDE.duplicated().sum()}")

# 5. Data Validation
print(f"Unique departments: {dfDE['department_id'].nunique()}")
print(f"Unique employees: {dfDE['employee_id'].nunique()}")



"""## Dep Data"""

from google.colab import files
uploaded = files.upload()

import pandas as pd

dfD = pd.read_csv("department.csv")
dfD.head()

# 1. Describe (categorical data)
print(dfD.describe(include='object'))

# 2. Info
print(dfD.info())

# 3. Null values
print(dfD.isnull().sum())

# 4. Duplicates
print(f"Duplicate rows: {dfD.duplicated().sum()}")

# 5. Data Validation
print(f"Unique departments: {dfD['dept_name'].nunique()}")

"""## Salary Data"""

from google.colab import files
uploaded = files.upload()

import pandas as pd
6
dfS = pd.read_csv("salary.csv")
dfS.head()

# 1. Describe (categorical data)
print(dfS.describe(include='object'))

# 2. Info
print(dfS.info())

# 3. Null values
print(dfS.isnull().sum())

# 4. Duplicates
print(f"Duplicate rows: {dfS.duplicated().sum()}")

# 5. Data Validation
print(f"Unique departments: {dfS['employee_id'].nunique()}")

"""## Department_manager Data"""

from google.colab import files
uploaded = files.upload()

import pandas as pd

dfDM = pd.read_csv("department_manager.csv")
dfDM.head()

print(dfDM.describe(include='object'))

# 2. Info
print(dfDM.info())

# 3. Null values
print(dfDM.isnull().sum())

# 4. Duplicates
print(f"Duplicate rows: {dfDM.duplicated().sum()}")

# 5. Data Validation
print(f"Unique departments: {dfDM['department_id'].nunique()}")
print(f"Unique employees: {dfDM['employee_id'].nunique()}")

"""## Title Data

"""

from google.colab import files
uploaded = files.upload()

import pandas as pd

dfT = pd.read_csv("title.csv")
dfT.head()

print(dfT.describe(include='object'))
print(dfT.info())
print(dfT.isnull().sum())
print(f"Duplicate rows: {dfT.duplicated().sum()}")
print(f"Unique titles: {dfT['title'].nunique()}")

"""## Current_employee_snapshot Data




"""

from google.colab import files
uploaded = files.upload()

import pandas as pd

dfCE = pd.read_csv("current_employee_snapshot.csv")
dfCE.head()

print(dfCE.describe(include='object'))
print(dfCE.info())
print(dfCE.isnull().sum())
print(f"Duplicate rows: {dfCE.duplicated().sum()}")



"""**Cases Study Invistgation.**"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
dfE['hire_date'] = pd.to_datetime(dfE['hire_date'])
dfDE['from_date'] = pd.to_datetime(dfDE['from_date'])
dfDE['to_date'] = pd.to_datetime(dfDE['to_date'].replace("9999-01-01", pd.NaT))

# Today's date
today = pd.Timestamp(datetime.today())

# Merge employee and department info
emp_dept = pd.merge(dfDE, dfE, left_on='employee_id', right_on='id', how='left')
emp_dept['tenure_years'] = (today - emp_dept['hire_date']).dt.days // 365

# Keep only most recent department assignment per employee
emp_dept_latest = emp_dept.sort_values('from_date').drop_duplicates('employee_id', keep='last')
emp_dept_named = pd.merge(emp_dept_latest, dfD, left_on='department_id', right_on='id', how='left')

# Group by department and calculate average tenure
dept_tenure = emp_dept_named.groupby('dept_name').agg(
    average_tenure_years=('tenure_years', 'mean')
).sort_values(by='average_tenure_years', ascending=False)

# Plot
plt.figure(figsize=(10, 6))
sns.barplot(data=dept_tenure.reset_index(), x='average_tenure_years', y='dept_name', palette='crest')
plt.title("ðŸ“Š Average Employee Tenure by Department", fontsize=14)
plt.xlabel("Average Tenure (Years)")
plt.ylabel("Department")
plt.grid(axis='x', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

import pandas as pd
from datetime import datetime

# Load and parse dates, handling '9999-01-01'
dfE['hire_date'] = pd.to_datetime(dfE['hire_date'])
dfDE['from_date'] = pd.to_datetime(dfDE['from_date'])
dfDE['to_date'] = dfDE['to_date'].replace('9999-01-01', pd.NaT)
dfDE['to_date'] = pd.to_datetime(dfDE['to_date'])

# Today's date for tenure calculation
today = pd.Timestamp(datetime.today())

#SQL
# Step 1: Merge employees with their department assignments
emp_dept = pd.merge(dfDE, dfE, left_on='employee_id', right_on='id', how='left')

'''
dfDE: contains department assignments â†’ has employee_id, department_id, from_date, to_date

dfE: contains employee info â†’ has id, hire_date, gender, etc.
'''

# Step 2: Calculate employee total tenure (years)
emp_dept['tenure_years'] = (today - emp_dept['hire_date']).dt.days // 365

# Step 3: Use most recent assignment only (to avoid duplication)
emp_dept_latest = emp_dept.sort_values('from_date').drop_duplicates('employee_id', keep='last')

# Step 4: Merge with department names
emp_dept_named = pd.merge(emp_dept_latest, dfD, left_on='department_id', right_on='id', how='left')

# Step 5 (Updated): Group by department and compute both average tenure and employee count
dept_summary = emp_dept_named.groupby('dept_name').agg(
    average_tenure_years=('tenure_years', 'mean'),
    employee_count=('employee_id', 'nunique')
).sort_values(by='average_tenure_years', ascending=False)

# Step 6: Show results
print("\nðŸ“Š Department Summary (Average Tenure + Employee Count):")
print(dept_summary)

# Optional: Bar Plot
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
dept_summary.plot(kind='barh', color='steelblue')
plt.title("Average Tenure by Department")
plt.xlabel("Years")
plt.gca().invert_yaxis()
plt.grid(axis='x', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

dfS.columns

# Step 1: Merge salaries with employee info
emp_salary = pd.merge(dfS, dfE, left_on='employee_id', right_on='id', how='left')

# Step 2: Filter most recent salary entry for each employee
emp_salary_latest = emp_salary.sort_values('to_date').drop_duplicates('employee_id', keep='last')

# Step 3: Merge with latest department assignment
emp_dept_salary = pd.merge(emp_salary_latest, emp_dept_latest, on='employee_id', how='left')

# Step 4: Merge with department names
emp_dept_salary_named = pd.merge(emp_dept_salary, dfD, left_on='department_id', right_on='id', how='left')

# Step 5: Group by department name and sum salaries
dept_salary_total = emp_dept_salary_named.groupby('dept_name')['amount'].sum().sort_values(ascending=False)

# Step 6: Display result
print("\nðŸ’° Total Salary Paid per Department:")
print(dept_salary_total)

# Step 7: Get top department
top_salary_dept = dept_salary_total.idxmax()
top_salary_value = dept_salary_total.max()

print(f"\nðŸ† Department with Highest Salary Payout: {top_salary_dept} (${top_salary_value:,.2f})")

import matplotlib.pyplot as plt
import seaborn as sns

# Step 1: Reset index to convert Series to DataFrame
dept_salary_total_df = dept_salary_total.reset_index()
dept_salary_total_df.columns = ['Department', 'Total Salary']

# Step 2: Set visual style
plt.figure(figsize=(12, 6))
sns.set(style="whitegrid")

# Step 3: Bar plot
sns.barplot(
    data=dept_salary_total_df,
    x='Total Salary',
    y='Department',
    palette='viridis'
)

# Step 4: Add value labels
for index, value in enumerate(dept_salary_total_df['Total Salary']):
    plt.text(value + 1000, index, f"${value:,.0f}", va='center')

# Step 5: Titles and labels
plt.title("ðŸ’° Total Salary Paid per Department", fontsize=16)
plt.xlabel("Total Salary (USD)")
plt.ylabel("Department")

# Step 6: Show plot
plt.tight_layout()
plt.show()

emp_salary_latest = dfS.sort_values('to_date').drop_duplicates('employee_id', keep='last')

emp_dept_latest = dfDE.sort_values('from_date').drop_duplicates('employee_id', keep='last')

emp_dept_salary = pd.merge(emp_salary_latest, emp_dept_latest, on='employee_id', how='left')
emp_dept_salary_named = pd.merge(emp_dept_salary, dfD, left_on='department_id', right_on='id', how='left')
emp_dept_salary_named = pd.merge(emp_dept_salary_named, dfE[['id', 'first_name', 'last_name']], left_on='employee_id', right_on='id', how='left')
emp_dept_salary_named['full_name'] = emp_dept_salary_named['first_name'] + ' ' + emp_dept_salary_named['last_name']
top10_per_dept = (
    emp_dept_salary_named.sort_values(['dept_name', 'amount'], ascending=[True, False])
    .groupby('dept_name')
    .head(10)
    [['dept_name', 'employee_id', 'full_name', 'amount']]
)
print(top10_per_dept)

import seaborn as sns
import matplotlib.pyplot as plt

development_top10 = top10_per_dept[top10_per_dept['dept_name'] == 'Development']

plt.figure(figsize=(10, 6))
sns.barplot(data=development_top10, x='amount', y='full_name', palette='rocket')
plt.title("ðŸ’¼ Top 10 Paid Employees in Development")
plt.xlabel("Salary (USD)")
plt.ylabel("Employee")
plt.tight_layout()
plt.show()

dfS['from_date'] = pd.to_datetime(dfS['from_date'])
dfS['year'] = dfS['from_date'].dt.year
salary_growth = dfS.groupby('year')['amount'].mean().reset_index()
salary_growth.columns = ['Year', 'Average_Salary']
print(salary_growth.head())

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(12, 6))
sns.lineplot(data=salary_growth, x='Year', y='Average_Salary', marker='o', color='royalblue')
plt.title("ðŸ“ˆ Average Salary Growth Over Time", fontsize=16)
plt.xlabel("Year")
plt.ylabel("Average Salary (USD)")
plt.grid(True, linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

from datetime import datetime
import pandas as pd

dfE['hire_date'] = pd.to_datetime(dfE['hire_date'])
dfDE['from_date'] = pd.to_datetime(dfDE['from_date'])
dfDE['to_date'] = pd.to_datetime(dfDE['to_date'].replace("9999-01-01", pd.NaT))

today = pd.Timestamp(datetime.today())
dfDE['to_date'].fillna(today, inplace=True)

dfDE['tenure_days'] = (dfDE['to_date'] - dfDE['from_date']).dt.days
dfDE['tenure_years'] = dfDE['tenure_days'] / 365

df_turnover = pd.merge(dfDE, dfD, left_on='department_id', right_on='id', how='left')
turnover_stats = df_turnover.groupby('dept_name')['tenure_years'].mean().sort_values()
print("ðŸ“‰ Departments with Highest Turnover (Lowest Tenure):")
print(turnover_stats)

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 6))
sns.barplot(x=turnover_stats.values, y=turnover_stats.index, palette='Reds_r')
plt.title("ðŸ“‰ Average Tenure by Department (Lower = Higher Turnover)", fontsize=14)
plt.xlabel("Average Tenure (Years)")
plt.ylabel("Department")
plt.grid(axis='x', linestyle='--', alpha=0.6)
plt.tight_layout()
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

title_gender_count = dfT.merge(dfE, left_on='employee_id', right_on='id') \
                        .groupby(['title', 'gender'])['employee_id'] \
                        .count().reset_index()

plt.figure(figsize=(12, 6))
sns.barplot(data=title_gender_count, x='title', y='employee_id', hue='gender')
plt.title('Employee Count by Title & Gender')
plt.xlabel('Job Title')
plt.ylabel('Number of Employees')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

dfT['from_date'] = pd.to_datetime(dfT['from_date'], errors='coerce')
dfT['to_date'] = pd.to_datetime(dfT['to_date'], errors='coerce')

dfT.dropna(subset=['from_date', 'to_date'], inplace=True)

multi_title = dfT.groupby('employee_id').filter(lambda x: len(x) > 1)
multi_title['years_in_position'] = (multi_title['to_date'] - multi_title['from_date']).dt.days / 365.25

merged = multi_title.merge(dfDE, on='employee_id').merge(dfD, left_on='department_id', right_on='id')

promotion_timeline = merged.groupby('dept_name')['years_in_position'].mean().sort_values()

plt.figure(figsize=(10, 6))
promotion_timeline.plot(kind='barh', color='teal')
plt.title('Average Years to Promotion per Department')
plt.xlabel('Years')
plt.tight_layout()
plt.show()

dfE['hire_year'] = dfE['hire_date'].dt.year
hire_trend = dfE['hire_year'].value_counts().sort_index()

plt.figure(figsize=(10, 6))
hire_trend.plot(kind='line', marker='o')
plt.title('Number of Employees Over Time')
plt.xlabel('Hire Year')
plt.ylabel('Number of Hires')
plt.grid(True)
plt.tight_layout()
plt.show()

dfs = pd.read_csv('salary.csv')
df_salary_gender = dfs.merge(dfE[['id', 'gender']], left_on='employee_id', right_on='id')
df_salary_dept = df_salary_gender.merge(dfDE, on='employee_id').merge(dfD, left_on='department_id', right_on='id')

gap = df_salary_dept.groupby(['dept_name', 'gender'])['amount'].mean().unstack()

gap.plot(kind='bar', figsize=(12, 6))
plt.title('Salary Gap by Gender per Department')
plt.ylabel('Average Salary')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

dfE['hire_date'] = pd.to_datetime(dfE['hire_date'], errors='coerce')

dfs = dfs[dfs['to_date'] < '2100-01-01']
dfs['to_date'] = pd.to_datetime(dfs['to_date'], errors='coerce')

today = pd.Timestamp.today()
emp_salary = pd.merge(dfs, dfE[['id', 'hire_date']], left_on='employee_id', right_on='id', how='left')
emp_salary['tenure_years'] = ((today - emp_salary['hire_date']).dt.days) / 365.25

latest_salary = emp_salary.sort_values('to_date').drop_duplicates('employee_id', keep='last')
plt.figure(figsize=(10, 6))
sns.boxplot(data=latest_salary, x=pd.cut(latest_salary['tenure_years'], bins=5), y='amount')
plt.title('Salary Compression Analysis (Tenure vs Salary)')
plt.xlabel('Tenure Range (Years)')
plt.ylabel('Salary')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

=df_managers = dfT[dfT['title'].str.lower().str.contains('manager')]

df_manager_info = df_managers.merge(dfE[['id', 'gender']], left_on='employee_id', right_on='id')
manager_promotions = dfT.merge(df_manager_info[['employee_id', 'gender']], how='inner', left_on='employee_id', right_on='employee_id') \
                        .groupby('gender').size().reset_index(name='promotions_given')

plt.figure(figsize=(8, 6))
sns.barplot(data=manager_promotions, x='gender', y='promotions_given', palette='coolwarm')
plt.title('Manager Gender vs Promotions Given')
plt.xlabel('Manager Gender')
plt.ylabel('Number of Promotions Given')
plt.tight_layout()
plt.show()

dfE['hire_date'] = pd.to_datetime(dfE['hire_date'])
dfT['to_date'] = pd.to_datetime(dfT['to_date'])
dfs['to_date'] = pd.to_datetime(dfs['to_date'])

promotions = dfT.groupby('employee_id').size().reset_index(name='num_titles')
promotions['num_promotions'] = promotions['num_titles'] - 1
latest_salary = dfs.sort_values('to_date').drop_duplicates('employee_id', keep='last')
merged = dfE.merge(promotions, left_on='id', right_on='employee_id', how='left') \
            .merge(latest_salary[['employee_id', 'amount']], on='employee_id', how='left')

merged['tenure'] = (pd.Timestamp.today() - merged['hire_date']).dt.days / 365.25

merged['risk_score'] = 0
merged.loc[merged['tenure'] < 2, 'risk_score'] += 1
merged.loc[merged['amount'] < merged['amount'].median(), 'risk_score'] += 1
merged.loc[merged['num_promotions'].fillna(0) == 0, 'risk_score'] += 1
df_risk = merged.merge(dfDE, left_on='employee_id', right_on='employee_id').merge(dfD, left_on='department_id', right_on='id')
risk_heat = df_risk.groupby('dept_name')['risk_score'].mean().sort_values()

plt.figure(figsize=(10, 6))
sns.heatmap(risk_heat.to_frame().T, cmap='Reds', annot=True)
plt.title('Average Attrition Risk Score per Department')
plt.yticks([])
plt.tight_layout()
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

dfE['birth_date'] = pd.to_datetime(dfE['birth_date'])
dfT['from_date'] = pd.to_datetime(dfT['from_date'])
dfT['to_date'] = pd.to_datetime(dfT['to_date'])
today = pd.Timestamp.today()
dfE['age'] = (today - dfE['birth_date']).dt.days / 365.25
promotion_count = dfT.groupby('employee_id').size().reset_index(name='title_count')
promotion_count['num_promotions'] = promotion_count['title_count'] - 1
df_age_promo = dfE.merge(promotion_count, left_on='id', right_on='employee_id')
avg_age_by_promo = df_age_promo.groupby('num_promotions')['age'].mean().reset_index()

plt.figure(figsize=(10, 6))
sns.lineplot(data=avg_age_by_promo, x='num_promotions', y='age', marker='o')
plt.title('Average Age vs Number of Promotions')
plt.xlabel('Number of Promotions')
plt.ylabel('Average Age')
plt.tight_layout()
plt.show()

import pandas as pd
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score
latest_title = dfT.sort_values('to_date').drop_duplicates('employee_id', keep='last')[['employee_id', 'title']]
latest_dept = dfDE.sort_values('from_date').drop_duplicates('employee_id', keep='last')[['employee_id', 'department_id']]
latest_dept_named = latest_dept.merge(dfD, left_on='department_id', right_on='id')[['employee_id', 'dept_name']]
latest_salary = dfs.sort_values('to_date').drop_duplicates('employee_id', keep='last')[['employee_id', 'amount']]

promotions = dfT.groupby('employee_id').size().reset_index(name='title_count')
promotions['num_promotions'] = promotions['title_count'] - 1
merged = dfE.copy()
merged['tenure'] = (pd.Timestamp.today() - pd.to_datetime(merged['hire_date'])).dt.days / 365.25
merged = merged.merge(latest_title, left_on='id', right_on='employee_id', how='left') \
               .merge(latest_dept_named, on='employee_id', how='left') \
               .merge(latest_salary, on='employee_id', how='left') \
               .merge(promotions[['employee_id', 'num_promotions']], on='employee_id', how='left')

merged['risk_score'] = 0
merged.loc[merged['tenure'] < 2, 'risk_score'] += 1
merged.loc[merged['amount'] < merged['amount'].median(), 'risk_score'] += 1
merged.loc[merged['num_promotions'].fillna(0) == 0, 'risk_score'] += 1

df_model = merged[['gender', 'title', 'dept_name', 'tenure', 'amount', 'num_promotions', 'risk_score']].dropna()

X = df_model.drop(columns='risk_score')
y = df_model['risk_score']

X_encoded = X.copy()
cat_cols = ['gender', 'title', 'dept_name']
for col in cat_cols:
    le = LabelEncoder()
    X_encoded[col] = le.fit_transform(X_encoded[col])

smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_encoded, y)

X_train, X_test, y_train, y_test = train_test_split(
    X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled
)

model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred))
print("Accuracy:", accuracy_score(y_test, y_pred))

from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score

df_model = merged[['gender', 'title', 'dept_name', 'tenure', 'amount', 'num_promotions', 'risk_score']].dropna()

X = df_model.drop(columns='risk_score')
y = df_model['risk_score']
X_encoded = X.copy()
cat_cols = ['gender', 'title', 'dept_name']
for col in cat_cols:
    le = LabelEncoder()
    X_encoded[col] = le.fit_transform(X_encoded[col])
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_encoded, y)
X_train, X_test, y_train, y_test = train_test_split(
    X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled
)

model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

import joblib
joblib.dump(model, "risk_model.pkl")

df.to_csv("employee.csv", index=False)
import joblib
joblib.dump(model, "rf_model.pkl")